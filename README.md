## Join Base Algorithms
### Apriori Algorithm

It is based on "every sub (k-1)-Itemset of frequent k-Itemset must be frequent" 


It mainly has two steps involved:-  
**Method 1. Candidate generation process**   
a)Eliminate those itemsets from Item Set generation process whole suport count falls below threshold 

**Method 2)Item Set Generation** . 

a)Generate (n) length itemsets from (n-1) length Candidate generation itemsets.This can be done by joining k-1 length itemsets together based ona condition that its first k-3 items are similar 

b) Get the support count of all the generated item sets by going through trasaction database
  
This process continues until Candidate generation itemsets become null

Limitations:-  

  1)Complete Item set generation ,which takes up large memmory and execution time . 
  
  2)Candidate generation process requires excessive database scans for gettting the Support count . 
  
2)Rapid Association Rule Mining (RARM)
It uses a novel tree data structure known as Support-Ordered Trie Itemset (SOTrieIT).

This is mainly devloped as Apriori Algorith takes lot of time and memmory for generation 1 and 2 length item sets.By this process we can get those done quickly and efficiently.Then follow it up with the same Apriori method

  A TrieIT is a set of nodes in tree consisting of 2 values (Item Label and Item Support). SOTrieIT
is a sorted ordered TrieIT in which nodes are sorted with their respective support count. Highest support item
moves to the left most nodes and lowest support node is at the right most position in the tree. 

To Construct SOTrieIT tree structure,
a)from each transaction only 1-Itemset and 2-Itemset are extracted. 
b)For example from TID1={I1,I2,I5} possible information extracted will be {(I1),(I2),(I5),(I1,I2),(I1,I5),(I2,I5)}.
c)If those items that have already exist in the tree, their support count is increased by 1,
d)whereas items that are currently do not exist in tree,create a node with label of item name and support count 1.
e)After Constructing SOTrieIT tree, it is sorted according to their respective support count

Limitaions:-
1)It is difficult to use RARM in interactive mining because if the user support threshold is changed, the whole process will have to repeat. 
2)RARM is also not suitable for incremental mining, as database size is continuously increasing with addition of new transaction;whole process needs to repeat again and again.


3)Equivalence CLAss Transformation (ECLAT)
It uses vertical database format whereas in Apriori and RARM horizontal data format (TranscationId, Items) has been used, in which transaction ids are explicitly listed

While in vertical data format (Items, TransactionId) Items with their list of transactions are maintained

ECLAT algorithm with set intersection property uses depth-first search algorithm For example:-

In first scan of database a TID (TranscationId) list is maintained for each single item. k+1 Itemset can be generated from k Itemset using apriori property and depth first search computation.
(k+1)-Itemset is generated by taking intersection of TID-set of frequent k-Itemset .This process continues, until no candidate Itemset can be found

Limitaions:-
When tid-list is large at that time it takes more space to store candidate set. It needs more time for intersection when Tid list is large

4)Frequent Pattern (FP) Growth Algorithm
It deals with the two main drawbacks of Apriori algorithm, a compressed data structure named as FPtree is constructed, which is prefix-tree structure storing quantifiable information about frequent patterns. 
Based on FP tree a frequent pattern growth algorithm was developed

Step-1)
In first step a frequent pattern tree is constructed scanning database twice.
In first pass of database, data is scanned and support count for each item is calculated, infrequent patterns are deleted from the list and remaining patterns are sorted in descending order. 
In 2nd pass of database, FP Tree is build.
Step-2)
Using FP growth algorithm, frequent patterns are extracted from FP Tree.

Limitations:-
FP-Tree is expensive to build Comsumes more memory due to its divide and conquer approach
It is difficult to use in incremental mining, as new transactions are added to the database, FP tree needs to be updated and the whole process needs to repeat.

5) Associated sensor pattern mining of data stream ASPMS

ASMPS technique can capture the recent data form a data stream efficiently by using the compact ASPS-tree structure.
It needs only a single-pass over the sensor data stream for performing tree construction and mining process

(ASPMS) algorithm is used for sliding window based associated sensor patterns for mining. 
This algorithm can capture important knowledge from the stream contents for the current window of the sensor in a batch-by-batch manner.
Inside the nodes of an ASPStree in a sensor appearance order and then restructure the tree in a frequency-descending order. Then finally compress the tree by merging the same support sensor node in a single node in each branch of the tree. 
This technique has two phases: Tree construction and mining associated sensor patterns.
Tree construction phase is further divided into two sub phases; insertion phase and restructuring & compressing phase


6)The DHP Algorithm (Direct Hashing and Pruning) 
DHP can be used for efficient large itemset generation. It has two major features: 
1)efficient generation for large itemsets
2)effective reduction on transaction database. 
"It uses hashing technique"

DHP is, in orders of magnitude, smaller than that of by Apriori method.Thus improving the performance bottleneck of the whole process. It Uses pruning technique to reduce the size of the database progressively

Method:-
In k-iteration, hash all “appearing” k+1 itemsets in a hashtable, count all the occurrences of an itemset in the correspondent bucket. In k+1 iteration, examine each of the candidate itemset to see if its correspondent bucket value is above the support

7)









